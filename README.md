üå¶Ô∏è Pipeline d'Orchestration GraphCast - √âtape 13
Ce module constitue le "cerveau" du projet. Il orchestre l'extraction des donn√©es d'initialisation depuis PostgreSQL, l'inf√©rence via l'API GraphCast et l'ingestion des r√©sultats finaux.

üöÄ Fonctionnement du Pipeline
Le script principal trigger_and_ingest_forecast.py coordonne les √©tapes suivantes :

Pr√©paration : Calcul de la date cible (J-6) et extraction des snapshots T-6h et T0.

Inf√©rence : Envoi d'un payload JSON √† l'API FastAPI (port 8001).

Ingestion : Stockage de 80 points de pr√©vision (4 horizons : T+6h, T+12h, T+18h, T+24h) dans la base PostgreSQL.

üìÇ Structure du Projet
Plaintext

/Etape13Forecasting_Orchestration
‚îú‚îÄ‚îÄ trigger_and_ingest_forecast.py  # Orchestrateur principal
‚îú‚îÄ‚îÄ modules/
‚îÇ   ‚îú‚îÄ‚îÄ data_preparator.py          # Extraction SQL des donn√©es ERA5
‚îÇ   ‚îú‚îÄ‚îÄ model_api_client.py         # Client HTTP pour l'API GraphCast
‚îÇ   ‚îî‚îÄ‚îÄ prediction_db_ingestion.py  # Ingestion des pr√©visions en base
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ settings.py                 # Configuration DB et API
‚îî‚îÄ‚îÄ logs/                           # Fichiers de suivi du pipeline
üõ†Ô∏è Installation & Configuration
1. Pr√©requis
Docker (avec le conteneur trading_pg_db actif).

API GraphCast (Etape 12) lanc√©e sur le port 8001.

Biblioth√®ques Python : psycopg2, requests.

2. Lancer le pipeline manuellement
PowerShell

python trigger_and_ingest_forecast.py
üìÖ Planification (Automation)
Sur Windows (Planificateur de t√¢ches)
Cr√©er une nouvelle t√¢che nomm√©e GraphCast_Pipeline.

D√©clencheur : Quotidien, r√©p√©ter toutes les 6 heures ind√©finiment.

Action : D√©marrer le programme python.exe.

Argument : C:\Chemin\Vers\Etape13\trigger_and_ingest_forecast.py.

Sur Linux (Cron)
Ajouter la ligne suivante via crontab -e :

Bash

0 */6 * * * /usr/bin/python3 /chemin/ton_projet/trigger_and_ingest_forecast.py >> /chemin/ton_projet/logs/pipeline.log 2>&1
üîç V√©rification des donn√©es
Pour confirmer que les pr√©visions sont bien stock√©es en base :


docker exec -it trading_pg_db psql -U dev_user -d trading_data -c "SELECT forecast_time, COUNT(*), AVG(value) FROM predictions GROUP BY forecast_time ORDER BY forecast_time;"